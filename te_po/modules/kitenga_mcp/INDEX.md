# MCP Services - Complete File Index

Your complete MCP architecture is ready. Here's what was created:

## ğŸ“‹ Complete File List

```
mcp_services/
â”œâ”€â”€ ğŸ“„ README.md                     â† Start here
â”œâ”€â”€ ğŸ“„ SUMMARY.txt                   â† Visual overview
â”œâ”€â”€ ğŸ“„ QUICK_REFERENCE.md            â† Quick start guide
â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md               â† How it's designed
â”œâ”€â”€ ğŸ“„ INTEGRATION_GUIDE.md           â† Continue + GPT Build setup
â”œâ”€â”€ ğŸ“„ DEPLOYMENT_CHECKLIST.md        â† Phase-by-phase checklist
â”œâ”€â”€ ğŸ“„ config.yaml                   â† Continue IDE configuration
â”‚
â”œâ”€â”€ ğŸ—‚ï¸  tepo/
â”‚   â”œâ”€â”€ server.py                    â†’ MCP server (517 lines)
â”‚   â”œâ”€â”€ schema.json                  â†’ Service schema (permanent context)
â”‚   â””â”€â”€ tools.json                   â†’ 12 tool definitions
â”‚
â”œâ”€â”€ ğŸ—‚ï¸  git/
â”‚   â”œâ”€â”€ server.py                    â†’ MCP server (579 lines)
â”‚   â”œâ”€â”€ schema.json                  â†’ GitHub API schema
â”‚   â””â”€â”€ tools.json                   â†’ 17 tool definitions
â”‚
â”œâ”€â”€ ğŸ—‚ï¸  render/
â”‚   â”œâ”€â”€ server.py                    â†’ MCP server (474 lines)
â”‚   â”œâ”€â”€ schema.json                  â†’ Render API schema
â”‚   â””â”€â”€ tools.json                   â†’ 8 tool definitions
â”‚
â”œâ”€â”€ ğŸ—‚ï¸  supabase/
â”‚   â”œâ”€â”€ server.py                    â†’ MCP server (513 lines)
â”‚   â”œâ”€â”€ schema.json                  â†’ Supabase API schema
â”‚   â””â”€â”€ tools.json                   â†’ 7 tool definitions
â”‚
â””â”€â”€ ğŸ—‚ï¸  shared/
    â””â”€â”€ __init__.py                  â†’ Shared utilities & context manager
```

## ğŸ“Š Statistics

- **Total Files**: 20
- **Python Code**: 751 lines across 4 servers
- **Schemas**: 4 (one per service)
- **Tool Definitions**: 44 tools total
- **Documentation**: 6 guides

| Service | Files | Lines | Tools |
|---------|-------|-------|-------|
| Te PÅ | 3 | 517 | 12 |
| Git | 3 | 579 | 17 |
| Render | 3 | 474 | 8 |
| Supabase | 3 | 513 | 7 |
| Shared | 1 | 70 | - |
| **Total** | **20** | **751** | **44** |

## ğŸš€ Reading Order

Start with these in order:

1. **[SUMMARY.txt](./SUMMARY.txt)** (5 min)
   - Visual overview of the architecture
   - What you got, why it works, quick start

2. **[QUICK_REFERENCE.md](./QUICK_REFERENCE.md)** (10 min)
   - Quick start instructions
   - Tool inventory
   - Integration overview

3. **[DEPLOYMENT_CHECKLIST.md](./DEPLOYMENT_CHECKLIST.md)** (5 min)
   - Phase-by-phase setup
   - Troubleshooting guide
   - Success criteria

4. **[INTEGRATION_GUIDE.md](./INTEGRATION_GUIDE.md)** (15 min)
   - Continue IDE setup
   - GPT Build configuration
   - Full workflow examples

5. **[ARCHITECTURE.md](./ARCHITECTURE.md)** (20 min)
   - Technical design details
   - Why persistence works
   - How to add new services

6. **[config.yaml](./config.yaml)** (copy to Continue)
   - Copy to `~/.continue/config.yaml`

## ğŸ¯ What Each File Does

### Server Files (*.py)

Each `server.py` implements the Model Context Protocol:
- Loads schema.json once (stays in memory)
- Loads tools.json
- Handles MCP protocol messages
- Calls external APIs
- Returns structured results

**Key Pattern**:
```python
class Service:
    def __init__(self):
        self.schema = load_json("schema.json")  # â† Permanent
        self.tools = load_json("tools.json")    # â† Permanent

    def call_tool(name, args):
        # Execute via API
        # Return result
```

### Schema Files (schema.json)

Each schema defines:
- Service description
- Available endpoints
- Input/output constraints
- Authentication requirements

**Stays in memory** - never reloaded. This is why context doesn't drop.

### Tools Files (tools.json)

Each tools file contains:
- Tool name (e.g., "tepo_kitenga_whisper")
- Description
- Category
- HTTP method and path
- Input schema with examples
- Output schema

**Permanent reference** - tools never change during execution.

### Documentation Files

| File | Purpose |
|------|---------|
| README.md | Overview and setup |
| SUMMARY.txt | Quick visual summary |
| QUICK_REFERENCE.md | Quick start guide |
| ARCHITECTURE.md | Technical design |
| INTEGRATION_GUIDE.md | Setup for Continue + GPT Build |
| DEPLOYMENT_CHECKLIST.md | Phase-by-phase deployment |
| config.yaml | Continue IDE configuration |

## âœ… Implementation Details

### Te PÅ Server (tepo/server.py)

```python
# Wraps Te PÅ backend API
# 12 tools: chat, OCR, vectors, memory, pipelines, kaitiaki, database
# Auth: Optional bearer token via TE_PO_AUTH_TOKEN
# Base URL: TE_PO_BASE_URL (local or Render)
```

**Key Tools**:
- Chat: `tepo_kitenga_whisper`
- Search: `tepo_vector_search`
- OCR: `tepo_ocr_scan`
- Memory: `tepo_memory_store`, `tepo_memory_query`
- Database: `tepo_db_*`

### Git Server (git/server.py)

```python
# Wraps GitHub API
# 17 tools: repos, branches, commits, files, PRs, issues, releases
# Auth: Required GITHUB_TOKEN
# Base URL: https://api.github.com (fixed)
```

**Key Tools**:
- Repos: `git_repo_info`, `git_list_branches`
- Files: `git_get_file`, `git_create_file`, `git_update_file`
- PRs: `git_list_pull_requests`, `git_create_pull_request`
- Issues: `git_list_issues`, `git_create_issue`
- Releases: `git_list_releases`, `git_create_release`

### Render Server (render/server.py)

```python
# Wraps Render API
# 8 tools: services, deployments, scaling, monitoring
# Auth: Required RENDER_API_KEY
# Base URL: https://api.render.com/v1 (fixed)
```

**Key Tools**:
- Services: `render_list_services`, `render_get_service`
- Deploys: `render_deploy`, `render_list_deploys`
- Scaling: `render_scale_service`
- Events: `render_list_events`

### Supabase Server (supabase/server.py)

```python
# Wraps Supabase REST API
# 7 tools: CRUD operations, RPC calls, file storage
# Auth: Required SUPABASE_KEY
# Base URLs: SUPABASE_URL/rest/v1 and /storage/v1
```

**Key Tools**:
- CRUD: `supabase_select`, `supabase_insert`, `supabase_update`, `supabase_delete`
- RPC: `supabase_rpc`
- Storage: `supabase_upload_file`, `supabase_list_buckets`

## ğŸ”§ How to Use

### For Continue IDE Integration

```bash
# 1. Copy config to Continue
cp mcp_services/config.yaml ~/.continue/config.yaml

# 2. Update paths and env vars in config.yaml

# 3. Restart Continue IDE

# 4. Type @tepo in chat to see tools
```

### For GPT Build Integration

```bash
# 1. Create custom API connector in GPT Build
#    Point to: https://your-render-url.onrender.com

# 2. Add endpoints:
#    - POST /kitenga/gpt-whisper
#    - POST /vector/search
#    - POST /ocr/scan
#    - POST /awa/pipeline

# 3. Test with chat
```

### For Local Testing

```bash
# Set environment variables
export TE_PO_BASE_URL="http://localhost:8010"
export GITHUB_TOKEN="your_token"
export RENDER_API_KEY="your_key"
export SUPABASE_URL="your_url"
export SUPABASE_KEY="your_key"

# Test server
python mcp_services/tepo/server.py

# Verify it loads and listens on stdio
```

## ğŸ“ Learning Resources

### Understanding MCP

The Model Context Protocol is how your IDE talks to external tools:

```
IDE (Continue)
    â†“
MCP Server (mcp_services/tepo/server.py)
    â†“
External API (https://your-render-url/...)
    â†“
Result back to IDE
```

### Understanding Schema Persistence

Schemas stay in memory because:

```python
# In server.__init__() - runs once at startup
self.schema = json.load(open("schema.json"))

# This stays in memory forever
# Never reloaded, never forgotten
# Always available for reference
```

This is why **context doesn't drop** - the schema is the permanent reference.

## ğŸ“ Getting Help

Each document is self-contained. If you're stuck:

- **"How do I set it up?"** â†’ QUICK_REFERENCE.md
- **"What's the architecture?"** â†’ ARCHITECTURE.md
- **"How do I deploy?"** â†’ DEPLOYMENT_CHECKLIST.md
- **"How do I add to Continue?"** â†’ INTEGRATION_GUIDE.md
- **"What's included?"** â†’ SUMMARY.txt

## ğŸ‰ Success Indicators

You'll know it's working when:

- âœ… Continue shows MCP tools with `@mcp`
- âœ… You can call `@tepo tepo_kitenga_whisper` and it works
- âœ… You can switch between services in same conversation
- âœ… Context stays solid (no "what was I doing?" moments)
- âœ… GPT Build can call endpoints
- âœ… No more context drops or loop tunnels

---

**Start with SUMMARY.txt, then QUICK_REFERENCE.md, then follow the DEPLOYMENT_CHECKLIST.md.**

You've got solid tools now. Use them well. ğŸ¤™
